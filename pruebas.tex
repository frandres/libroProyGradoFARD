\chapter{Pruebas y resultados} \label{chap:pruebas}

Con el objetivo de realizar las pruebas sobre el sistema se utilizaron tres dominios relacionados con el funcionamiento interno de la Universidad Simón Bolívar: las designaciones de cargos dentro de las unidades de la USB, los ingresos y ascensos dentro del escalafón de Profesores y la designación de Jurados para los Trabajos de Ascenso. Para trabajar con esos tres dominios se emplearon las Actas de Consejos Directivos y Actas de los Consejos Académico. La elección de los tres dominios se tomó buscando tener una variedad de estilos de texto semiestructurado para obtener resultados diversos sobre el funcionamiento del sistema elaborado. \\

La selección de los documentos se realizó sobre el conjunto de las actas de los Consejos Directivo y Académico de la Universidad Simón Bolívar desde el año 1998 hasta el año 2012. Esto permite que las pruebas se hagan sobre un conjunto de documentos que pueden tener variabilidad en su estilo, redacción y estructura. Del conjunto de actas en el intervalo de tiempo especificado, se hizo una preselección de los documentos para utilizar las actas de los consejos ordinarios. Adicionalmente, según cada dominio de aplicación se extrajeron las actas que sí contienen información sobre los dominios. Es decir, se utilizaron los documentos que contienen información sobre los dominios elegidos, descartando aquellas actas que no contenían texto de interés.\\

Una vez definidos los dominios se realizaron dos tipos de pruebas. En primer lugar se realizó un conjunto de pruebas unitarias sobre el Buscador Focalizado de Información, con el objetivo de probar el funcionamiento del extractor de información. Una vez verificado un buen funcionamiento de este módulo, se realizaron pruebas globales definiendo una serie de consultas sobre los tres dominios. La resolución de estas consultas requería el procesamiento de las mismas según lo especificado en el Determinador de Origen de Incompletitud y la búsqueda de información utilizando el Buscador Focalizado de Información.  \\


\section{Pruebas unitarias sobre el Buscador Focalizado de Información}

Para probar el Buscador Focalizado de Información se diseñaron dos pruebas por dominio. Por un lado de hicieron pruebas para el Preprocesador de Texto y en segunda instancia Pruebas para el Extractor Focalizado. 

\subsection{Pruebas del Preprocesador de Texto}

Para probar el preprocesador, se tomó un conjunto de archivos seleccionados aleatoriamente con uniformidad sobre los años. La muestra elegida fue de un tercio de la población total de actas existentes, para cada dominio. Para las designaciones se trabajó con 73 documentos, para las incorporaciones y ascensos dentro del escalafón se emplearon 77 documentos y para la designación de Trabajos de Jurado de Ascenso se utilizaron 49 documentos. \\

Las pruebas en esencia consistieron en ver si el fragmento de texto extraído por el preprocesador coincidía exactamente, estaba contenido, contenía o era completamente disjunto con el segmento de texto que debería ser extraído. Esto es: pueden verse ambos fragmentos de textos como secuencias de caracteres y se puede examinar si ambas secuencias coinciden por completo, tienen relaciones de contención o son completamente diferentes. \\

Esta prueba se hizo manualmente: se examinó el resultado de la extracción realizada por el preprocesador y se buscó dentro de cada documento el fragmento que debería extraerse. \\

Se definió como \emph{aprobado} si el fragmento extraído era completamente igual a la respuesta esperada (caso correcto) o si el fragmento extraído contiene a la respuesta esperada y algunos caracteres de más. Dicho caso se considera aprobado porque no importa que el fragmento extraído contenga texto de más siempre y cuando tenga la información necesaria para responder las consultas al hacer la búsqueda focalizada. Como \emph{no aprobado} se entienden los casos en los que la respuesta está incompleta o incorrecta. Un fragmento es incompleto si contiene sólo una parte de la información necesaria para responder una consulta. Se considera incorrecto si la información contenida en el fragmento no tiene nada que ver con la consulta. \\

En la tabla \ref{tabla-resultados-preprocesamientoDatosDesignacion} puede verse que el preprocesador obtuvo resultados aceptables: en general, se obtuvo una tasa de aprobados de como mínimo 93.5\%. El motivo por el cual se obtuvieron dichos resultados es que como se el preprocesador trabaja con expresiones regulares y se hace difícil diseñar expresiones que tengan un 100\% de efectividad.\\

Hay varios comentarios pertinentes sobre el trabajo con expresiones regulares. Sin embargo, por fines de brevedad se realizarán al final de esta sección luego de presentar las pruebas del extractor focalizado, que también utiliza expresiones regulares.\\

\begin{table}[h]
\caption{Resultados detallados la evaluación del Preprocesador de Textos}
\centering
\scriptsize
\begin{tabular*}{1\textwidth}{@{\extracolsep{\fill}} !{\vrule width 1pt} c !{\vrule width 1pt} c | c | c!{\vrule width 1pt} c | c | c!{\vrule width 1pt}}
\hline
Dominio & \multicolumn{3}{c!{\vrule width 1pt}}{\bf{Aprobados}} & \multicolumn{3}{c |}{\bf{No aprobados}}\\
\hline
 & Correctos & Con texto de más & \bf{Total aprobados} & Incompletos & Incorrectos & \bf{Total no aprobados}\\
\hline
Designaciones & 87.69\% & 7.69\% & \bf{95.39\%} & 3.07\% & 1.54\% & \bf{4.61\%}\\
\hline
Escalafón & 80.51\% & 12.98\% & \bf{93.6\%}  & 6.4\% & 0\% & \bf{6.4\%} \\
\hline
Jurados de Ascenso & 77.55\% & 16.32\% & \bf{93.88\%} & 0\% & 6.12\% & \bf{6.12\%} \\
\hline
\end{tabular*}
\label{tabla-resultados-preprocesamientoDatosDesignacion}
\end{table}

\subsection{Pruebas de Extractor Focalizado}

Para probar el extractor focalizado, se tomó al igual que en las pruebas del Preprocesador de texto un conjunto de prueba seleccionado aleatoriamente con uniformidad sobre los años. La muestra es de un tercio de la población total. Para hacer esto de cada archivo seleccionado, se tomaban hasta tres unidades de documento según lo explicado en la sección \ref{sect:implementacion-extractorFocalizado}. Dichas unidades fueron copiadas en un archivo de pruebas que posteriormente era leído por un módulo de pruebas que se encarga de probar el extractor focalizado automáticamente. \\

Una prueba individual consiste en hacer una búsqueda focalizada sobre un campo presente en una unidad de documento. Una unidad de documento da por lo tanto para hacer tantas pruebas como campos con valor tenga esa unidad. Si el dominio tiene por ejemplo 3 campos y se tiene una unidad de documento con dos campos, se realizan dos pruebas para esa unidad: una para cada campo. Las pruebas se hacen iterando entonces sobre cada uno de los campos con valores en la unidad y buscando extraer el valor del mismo utilizando un contexto de extracción dado por los valores de los campos que sí se tienen. \\ 

Para emular condiciones en las que no se tienen todos los valores de los campos relacionados con una unidad - esto es, que a pesar de que la unidad contenga valores para varios campos a la hora de hacer la búsqueda focalizada el \emph{contexto de extracción dado por la consulta} no contenga todos esos valores -, los contextos de extracción se construyeron con un subconjunto de los valores de los campos presentes en la unidad de documento. Este subconjunto se determina aleatoriamente: se genera un número al azar y si ese número es mayor que una \emph{probabilidad de tener cada campo} se incluye en el contexto de extracción. De esta manera se evitar suponer para estas pruebas que los contextos de extracción son completos.\\

Las pruebas se realizaron iterando el valor de la \emph{probabilidad de tener cada campo}. Se tomaron como \emph{probabilidades de tener cada campo} 1; 0.66 y 0.33. Adicionalmente, se iteró también sobre el \emph{Minimum Hit Measure} (según lo definido en la sección \ref{sect:implementacion-extractorFocalizado}) con el objetivo de probar el efecto que tiene la elección de este parámetro en el funcionamiento del extractor focalizado. Los valores sobre los que se realizaron las pruebas son: 1; 0.66 y .33.\\

De esta manera, y resumiendo, las pruebas se realizaron tomando tres unidades de documento de cada documento de cada dominio. Para cada unidad se itera sobre la \emph{probabilidad de tener cada campo} y el \emph{Minimum Hit Measure}. Los resultados fueron posteriormente totalizados por dominio y tabulados. \\

En el apéndice \ref{chap:apendiceb} se muestra la totalidad de los resultados obtenidos de las pruebas unitarias realizadas sobre el Extractor Focalizado. Con el objetivo de seleccionar resultados ilustrativos, para estas pruebas se ha decidido mostrar para cada dominio de información los resultados obtenidos con un valor del Unit Hit Measure de 0.66, mostrando los resultados obtenidos con las probabilidades de campo faltante de 0; 0.33 y 0.66. El motivo de esto es que se observó que dicho valor del Unit Hit Measure era representativo de los resultados obtenidos. Se consideró tomar el promedio de los tres resultados obtenidos según las probabilidades de campo faltante pero se decidió que el efecto de dichas probabilidades era bastante relevantes e importante, y por lo tanto conveniente de destacar.\\

De igual forma, para ilustrar el efecto del valor del Unit Hit Measure se decidió colocar los resultados obtenidos para valores de Unit Hit Measure de 0; 0.33 y 0.66 para el dominio de Designaciones.\\

En las tablas, \emph{Prob.} es la probabilidad de que no se tenga el valor de uno de los campos que se utilizan para hacer la extracción focalizada.

\emph{NOTA: Asegurate de referenciar a las tablas en el análisis de los resultados cuando toque volver aeste punto} 

\input{tablasEFIResultados}

Los resultados obtenidos varían muchísimo según las tres variables que entran en juego en este experimento: el dominio de información (al cual está asociado una semántica que determina a su vez un extractor especificado por expresiones regulares), el Unit Hit Measure (UHM) y la probabilidad (P) de que cada uno de los campos falten.\\

Puede verse en primera instancia como algunos campos obtenidos tuvieron una aprobación considerablemente alta: postergado en el Dominio Escalafón obtuvo un 98,46\% (tabla \ref{Resultados-tabla-resultados-EFEscalafon0.66}), escalafón en el caso de los jurados de ascenso 97,04\% (tabla \ref{Resultados-tabla-resultados-EFJuradosAscenso0.66}) y fecha de Designación en el caso del dominio Designación 98,88\% (tabla \ref{Resultados-tabla-resultados-EFDesignaciones0.66}). De igual forma, hay campos con precisión menor: nombre del Miembro Principal Externo en el caso de Jurados de Ascenso obtuvó 89,63\% (tabla \ref{Resultados-tabla-resultados-EFJuradosAscenso0.66}), el nombre del profesor ascendido en el caso de Escalafón 78,46\% (tabla \ref{Resultados-tabla-resultados-EFEscalafon0.66}), la calificación de la designación (el nombre del cargo y la unidad de la designación) 73,18\% (tabla \ref{Resultados-tabla-resultados-EFDesignaciones0.66}). \\

Todos estos valores anteriormente referenciados son representativos de cada uno de los tres dominios y se corresponden a las pruebas hechas con un UHM de 0.66 y P de 0,33. Esto parámetros son considerados representativos y válidos para sacar algunas conclusiones generales. Un UHM mínimo de 0.66 es empíricamente el mejor parámetro obtenido para realizar extracción en los documentos seleccionados. Una probabilidad de 0,33 es representativa ya que no supone ni que la Base de Datos contiene todos los campos (probabilidad 0) o que es muy poco densa (probabilidad de 0.66). En lo sucesivo se explicará brevemente los resultados obtenidos y el comportamiento del Extractor Focalizado. Al menos de que se indique lo contrario, al hablar de resultados puntuales se hará referencia a los resultados obtenidos con UHM de 0,66 y P de ,33. \\

\shadowbox{Profe: Copié algunas cosas que estaban aquí al capítulo de explicacion de las RE.}\\
\shadowbox{Pero creo que este parrafo que sigue es necesario en este punto, porque es análisis y no imp.}\\

En la sección \ref{sect:implementacion-regexp} se explicó cómo se diseñan las expresiones regulares. Refrescando lo dicho en esa sección, el diseño de las expresiones regulares consiste en elegir clases de caracteres que especifiquen delimitadores anteriorse y posteriores al fragmento de texto que se quiere extraer.  A pesar de la riqueza que dan las clases de caracteres,  las expresiones regulares pueden considerarse como reglas bastante rígidas y estáticas. Como no son el producto de un proceso de aprendizaje de máquina o de un mecanismo probabilístico, se basan en la configuración que haga el usuario y dependen muchísimo de que la regularidad observada al hacer la configuración sea generalizable a todos los documentos.\\ 

Esto es complicado en la medida en la que se haga más amplio el conjunto de documentos sobre los cuales se hace la extracción: a menudo la nomenclatura utilizada, el estilo de redacción, el formato de los documentos, el posicionamiento de la información dentro del documento cambia de un año a otro o inclusive de un mes a otro. La labor del usuario experto es generalizar al máximo las reglas con las que configura el extractor, pero en muchos casos es una tarea cercana a lo imposible.\\

En muchos casos es imposible generalizar los delimitadores y se depende del conocimiento del usuario experto y de los documentos utilizados para modelar el documento. Por ejemplo, el campo nombre de la designación es uno de los más dificiles para generalizar: el resultado obtenido es uno de los más bajos (70,95\%, véase la tabla \ref{Resultados-tabla-resultados-EFDesignaciones0.66}). El motivo de esto es que los delimitadores utilizados para definir este campo cambian muchísimo y es poco práctico compilar una lista con todos los posibles nombrse que puede tener una persona. \\

Por otro lado, hay campos que dada la regularidad de sus valores es fácil de modelar. Es el caso del nombre del escalafón en el dominio de Jurados de trabajo de Ascenso (que tiene tres valores posibles: titular, asociado y agregado), de las fechas (que se presentan típicamente en formatos dd/MM/aaaa, dd-mm-aaaa), si el ascenso es postergado o no (típicamente se identificamente con una frase del tipo: veredicto desfavorable, veredicto reprobatorio, rechazar dicho trabajo, entre otras). Dichos campos obtuvieron precisiones de 97.04\% (tabla \ref{Resultados-tabla-resultados-EFJuradosAscenso0.66}), 87.11 (promedio de los tres campos de tipo fecha presentes en los tres dominios, en todas las tablas mostradas) y 98.46\% (tabla \ref{Resultados-tabla-resultados-EFEscalafon0.66}), respectivamente. Nótese sin embargo, que la precisión de estos campos no es perfecta. En muchos casos una examinación de los resultados puntuales en estos campos indican errores de tipeo que explican los errores del orden del 1-2\%. En otros casos, como en las fechas, existen documentos en los que la fecha se escribe extensivamente en lugar de la sintaxis abreviada (15 de diciembre de mil novecientos noventa y nueve, por ejemplo, en lugar de 15-12-1999). \\

Otra observación que vale la pena hacer es el efecto que puede tener la estructura del documento y el posicionamiento de los campos dentro del mismo. Esto se puede apreciar en el dominio de designación de jurados de ascenso: los nombres de los miembros del jurado, campos del mismo tipo y que tienen todos el mismo formato (en esencia, el nombre), tienen resultados diferentes según el posicionamiento que tienen dentro del texto. El posicionamiento influye precisamente porque determina la selección de los delimitadores del documento; en ocasiones el usuario que construye las expresiones regulares puede beneficiarse de que un campo esté de último en el párrafo o que esté justo después de una palabra clave. \\

En el caso concreto de los jurados, el resultado promedio del porcentaje de aprobados de los nombres de los 5 jurados es de 94.8. El resultado del Miembro Principal Externo es sin embargo 89,63\% (véase la tabla \ref{Resultados-tabla-resultados-EFJuradosAscenso0.66}). Este resultado puede atribuirse a que las expresiones regulares óptimas para este campo fueron construidas esperando que el Miembro Principal Externo sea el último miembro a definirse; en los casos en los que no hay un miembro principal externo el último miembro es el miembro principal interno y por lo tanto se tiene una respuesta equivocada. \\

Hay también varios casos en los que delimitadores de una unidad de documento tienen errores. Como bien se ha dicho, una unidad de documento es un fragmento de texto que se refiere a una designación, ascenso o jurado de ascenso. Si se tiene más de una unidad en lo que el extractor reconoce como una (por problemas en los delimitadores de las mismas), se pierde toda la información de las unidades adicionales. Esto demuestra lo crítico que es construir las mejores expresiones regulares para delimitar unidades de documento. Quizás sea interesante probar otro mecanismo que no dependa de la existencia de unidades.  \\

En otro casos, el extractor no permite procesar corrrecciones registradas en los documentos. Es decir, puede ocurrir que en un acta se especifiquen correcciones sobre la información de una designación, ascenso o jurado que fue anunciado en un acta previa. De cierta manera, se tienen más de una unidad de documento que se refieren a un mismo hecho: la designación, el ascenso o el jurado inicial y las correcciones a los mismos. El extractor es incapaz de diferenciar entre ambos, aunque ambos tengan un UHM alto, y se queda con el primero que consiga. Esto podría solucionarse mejorando el extractor, de forma que pueda identificar cuando una unidad está vinculada a otra unidad presente en el conjunto de los documentos. Esta tarea no puede resolverse exclusivamente escribiendo mejores expresiones regulares: se tiene que introducir una forma de discriminar entre unidades con igual Unit Hit Measure.\\

Otro problema asociado al procesamiento por unidades de documento fue encontrado en el dominio de Designaciones. Se encontraron casos en los que hay múltiples designaciones para una misma persona para un mismo día, y que por lo tanto es imposible diferenciar como unidades diferentes. Esto es, si se tiene un dominio en el cual los contextos de extracción son iguales entre unidades de documentos que se refieren a cosas diferentes, se pierde información. Esta hipótesis sirve para explicar los resultados obtenidos en la calificación de la designación: 73,18\% (véase la tabla \ref{Resultados-tabla-resultados-EFDesignaciones0.66}). \\

Los resultados obtenidos son de esta manera bastante interesantes y la cantidad de información da para sacar varias conclusiones sobre la complejidad que supone la tarea de hacer extracción de información. La tecnología utilizada para hacer la extracción, expresiones regulares, supone retos adicionales y los resultados varían muchísimo según el campo. Es importante recordar que estos resultados son obtenidos en el contexto de documentos semi-estructurados y con una cierta regularidad en su estructura y redacción. Se hace significativamente más difícil hacer extracción en dominios con estilo de redacción más libre salvo para datos muy, muy puntuales. Esto es sin duda alguna uno de los motivos por los cuales las expresiones regulares han sido relegadas en el estudio de las áreas de Procesamiento de Lenguaje Natural y Extracción de Información. Hoy por hoy se apuesta más por métodos estocásticos y aprendizaje de máquina para realizar estas tareas. \\

Hasta ahora se ha analizado exclusivamente el comportamiento de las expresiones regulares según los dominios y los campos tomando en cuenta si el resultado obtenido es aprobado o no. Los resultados sin embargo pueden ser refinados en dos subcategorías dentro de las categorías aprobado y no aprobado. Dentro de la categoría aprobado se tiene que el resultado sea correcto (que sea una coincidencia exacta) o que la respuesta tenga texto de más (la respuesta obtenida contiene la respuesta correcta). Dentro de la categoría no aprobado se tienen incompletos (la respuesta correcta contiene a la respuesta obtenido) e incompleto (las respuestas obtenidas y correctas son completamente disjuntas). \\

Se decidió considerar estas categorías porque es ilustrativo e importante para profundizar el entendimiento de los resultados. Por ejemplo, el campo motivo de Designaciones registró un 20,11\% de respuestas aprobadas que, sin embargo, contienen texto de más. En este caso particular el motivo es que si bien es relativamente fácilmente conseguir el delimitador inicial del motivo de la designación, no es tan fácil conseguir el delimitador final. Por ende sucede a menudo que el extractor consigue el motivo pero captura texto adicional. \\

De igual forma hay varios campos que registraron porcentajes de incompletitud altos. El nombre del profesor en Designaciones registró un 28,49\% de incompletitud, lo cual quiere decir que si bien se extrajo parte del nombre, no se tuvo completo. El motivo de esto, nuevamente, es que dada la naturaleza del campo y de la posición del mismo en el documento, se hizó muy complicado elegir un delimitador final para el nombre que siempre lo capturara por completo. No es el caso de otros nombres de personas en otros dominios, que sí registraron tasas de acierto más deseables (nombres de los jurados, nombre del profesor que es ascendido, entre otros)\\

Por último, y no menos importante, la tasa de incorrectitud se refiere a los casos en los que la respuesta obtenida no tiene absolutamente nada que ver con la respuesta correcta. En casí todos los casos la proporción de respuestas es despreciable: en la mayoría de los casos es 0 (11 de 19),  el promedio de la proporción de incorrectitud de todos los campos 0,87\% y sólo en un campo pasa de 3\% (el nombre del miembro principal externo, con un 7,41\%). La existencia de estas respuestas incorrectas puede atribuirse a problemas en la selección de los delimitadores. \\

Queda en este punto comentar sobre el efecto que tiene la probabilidad de que falte un campo y el Hit Measure en los resultados obtenidos. Cómo se ha dicho anteriormente la probabilidad de que falte un campo es un elemento introducido en los experimentos para modelar el efecto que tiene la riqueza que tiene el contexto de extracción a la hora de hacer una búsqueda focalizada. Los archivos que se utilizaron para generar las pruebas contienen toda la información que se puede extraer de los documentos; sin embargo a la hora de hacer las pruebas, al incorporar el valor de cada campo se genera un número aleatorio; si es mayor que la probabilidad de la prueba se incorpora al contexto, de lo contrario no se incorpora. Esto permite emular condiciones normales de una extracción focalizada en la que no se tienen todos los valores de los campos. \\

El efecto de la probabilidad en los resultados obtenidos es bastante claro: se puede observar que conforme aumenta la probabilidad de que falte un campo (esto es, que el contexto de extracción sea menos rico) disminuye la proporción de resultados aprobados. Este comportamiento se puede observar en practicamente todos los campos y dominios. La disminución de la tasa de aprobación varía sin embargo bastante de acuerdo al campo: en algunos campos es del orden de las décimas mientras que en algunos otros es del orden de las decenas. Esto puede deberse a que existen campos que son más relevantes para poder discriminar entre unidades de documento. Si toca el caso de que el campo que se esté buscando es importante para identificar cada unidad, el efecto de que el contexto esté incompleto puede ser mayor. \\

Por último el UHM es una medida de qué tan exigente es el extractor focalizado al seleccionar unidades de documento. Esto es, mide qué porcentaje de campos contenidos en el contexto de extracción están presentes en cada unidad de documento: 1.0 indica que todos los valores del contexto están en la unidad, .66 y .33 que el 66\% y el 33\% están. En general en la medida en la que se flexibiliza la exigencia del extractor con el UHM, aumenta el número de resultados aprobados. El motivo de esto es que relajar la exigencia sólo permite que en caso de no tener mejores unidades se procesen unidades con una menor probabilidad de que se refieran al contexto de extracción. El extractor, como se ha dicho, ordena las unidades encontradas de acuerdo al unit hit measure y busca extraer primero el valor del campo faltante de las unidades con mayor UHM. \\

La importante del Unit Hit Measure es que de no tener exigencias sobre el mínimo valor de cada unidad se pueden tener resultados completamente incorrectos si el extractor no ubica las unidades de documento correctas y pasa a analizar unidades con menor UHM. \\

A manera de conclusión, el análisis aquí busca ilustrar, más que desmenuzar toda la información que se puede extraer de estas pruebas, los principales hallazgos producto de la utilización del extractor.Los resultados completos se pueden ver en el apéndice \ref{chap:apendiceb}.  Los hallazgos más importantes son que la utilización de expresiones regulares depende, como podría esperarse, fuertemente de la regularidad de un documento en su estructura y estilo de redacción, que está condicionada a errores humanos de tipeo y que depende de los delimitadores que un usuario experto pueda definir. De igual forma, depende fuertemente de cada uno de los campos y de la forma como se encuentran esos campos en el texto. Influye también la posición relativa de ellos.\\

La existencia de información previa, el contexto de extracción, que es precisamente la principal ventaja de la extracción focalizada, incide de forma determinante en el hallazgo de información faltante en la ontología.\\

\section{Pruebas globales del sistema}

Para realizar las pruebas globales del sistema, se preparó un conjunto de quince consultas para cada dominio de información definido previamente. La selección de las consultas para cada dominio de información fue realizada atendiendo varios criterios. Primeramente, se buscó que como mínimo hubiese una consulta que buscase resolver una incompletitud para cada atributo de los dominios. Es decir, que para cada atributo hubiese alguna consulta en la cual hubiese incompletitud por desconocimiento del valor de ese atributo en la base de datos. Además de esto, se eligieron consultas para probar el funcionamiento de operadores de agregación, incompletitud con atributos con relaciones de mayor o menor y cadenas AND-OR.

Aunado a esto, para realizar estas pruebas se llenó manualmente una base de datos para simular la existencia de información previa sobre los dominios de información. La selección de las tuplas que se utilizó para llenar la base de datos fue aleatoria. De igual manera, para cada tupla seleccionada para incorporar a la base de datos, se eligieron aleatoriamente algunos campos que si bien su valor era conocido fueron dejados en nulo. El objetivo de esto último es poder simular no sólo la inexistencia de alguna tupla en la base de datos, sino también la incompletitud de la información de cada tupla contenida. 

Una vez determinadas las consultas y construida una base de datos de prueba, se procedió a ejecutar las consultas. Se tomaron los datos obtenidos en base a la información contenida en la base de datos antes y despues de realizar la extracción focalizada de información y se contrastó con la respuesta correcta. La respuesta correcta fue determinada  examinando directamente los documentos.

De igual manera, para la realización de las pruebas se decidió tomar como Unit Hit Measure un valor de .1. 

A continuación se presentan los resultados obtenidos por dominio.

\input{tablasPruebasGlobales}
